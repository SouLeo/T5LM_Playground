## Disclaimer: THIS REPO IS VERY UNORGANIZED RN. THERE IS PERSONAL WORK ENTANGELED WITH THE WORK TOWARD ENABLING PROMPT TUNING. 

# T5LM_Playground
Exploring the work from Lester et al. (The Power of Scale for Parameter-Efficient Prompt Tuning) and recreating the experiments run by Schucher et al. (The Power of Prompt Tuning for Low-Resource Semantic Parsing)



Note to Self:

Current HuggingFace forum post opened: https://discuss.huggingface.co/t/confusion-about-t5lm-properties/13385


UMRF TODO:
1) issue with smaller commands vs longer, multi task commands from ALFRED
2) create new training w/ new prompt token embeddings for smaller commands?
